<h1 align="center">ğŸ” Parsing HTML  (versÃ£o 1.0)</h1>

<p align="center">
  <b>Extrator avanÃ§ado de links, hosts e anÃ¡lise de DNS diretamente em Bash</b><br>
  ğŸŸ¢ PortÃ¡vel â€¢ ğŸ” Seguro â€¢ âš¡ RÃ¡pido â€¢ ğŸŒ CompatÃ­vel com Linux/macOS
</p>

---

## âœ¨ Sobre o Projeto

Desenvolvi o **Parsing HTML 1.0** como uma ferramenta prÃ¡tica para auxiliar em atividades de anÃ¡lise, coleta de informaÃ§Ã£o e reconhecimento tÃ©cnico.  
A ideia Ã© simples: dado um site ou arquivo HTML, o script identifica links relevantes, extrai todos os hosts presentes e verifica automaticamente quais deles estÃ£o ativos via DNS.  

Criei essa versÃ£o priorizando seguranÃ§a, portabilidade e facilidade de uso â€” tudo em Bash puro, sem depender de bibliotecas externas.  
Ã‰ uma ferramenta leve, direta e pensada para integrar etapas iniciais de recon, OSINT ou pentests autorizados.


Ele permite:

- ğŸ“¥ Baixar pÃ¡ginas HTML (ou usar um arquivo local)
- ğŸ” Extrair todos os links Ãºteis (href, action)
- ğŸŒ Extrair hosts e domÃ­nios automaticamente
- ğŸ§ª Testar quais hosts estÃ£o vivos via DNS
- ğŸ¨ SaÃ­da amigÃ¡vel com cores, tags e organizaÃ§Ã£o
- ğŸ”’ Uso seguro com diretÃ³rios temporÃ¡rios (`mktemp`)

---

## ğŸš€ Funcionalidades

âœ” Suporte a URL ou arquivo HTML  
âœ” ExtraÃ§Ã£o robusta de links  
âœ” ExtraÃ§Ã£o inteligente de hosts (.com, .net, .gov, etc.)  
âœ” ResoluÃ§Ã£o DNS para detectar hosts ativos  
âœ” SaÃ­da com tags:

- ğŸŸ© **[LIVE]** â€“ Host ativo com IPv4/IPv6  
- ğŸŸ¨ **[RESOLVE]** â€“ Resolve parcialmente  
- ğŸŸ¥ **[DEAD]** â€“ NÃ£o responde  

âœ” NÃ£o usa `sed -i` â†’ compatÃ­vel com macOS e Linux  
âœ” Limpeza automÃ¡tica com `Ctrl + C` (trap integrada)

---

## ğŸ“¦ DependÃªncias

SÃ£o todas ferramentas comuns de terminal:

| Ferramenta | Usada para |
|-----------|------------|
| `wget` | Download da pÃ¡gina web |
| `host` | Teste de DNS |
| `grep` | ExtraÃ§Ã£o de padrÃµes |
| `sed` | NormalizaÃ§Ã£o de dados |
| `awk` | Processamento de colunas |
| `sort` | OrdenaÃ§Ã£o e deduplicaÃ§Ã£o |

O script verifica automaticamente a presenÃ§a delas.

---

## ğŸ“¥ InstalaÃ§Ã£o

```bash
git clone https://github.com/SEU-USUARIO/parsing-html.git
cd parsing-html
chmod +x parsing_html.sh

````

## ğŸ§  Uso

### ğŸ” Analisar uma pÃ¡gina pela URL

```shell
./parsing_html.sh https://exemplo.com
```

ğŸ“„ Analisar um arquivo HTML local

```shell
./parsing_html.sh -f pagina.html
```


ğŸ“˜ Ver ajuda

```shell
./parsing_html.sh -h
```

[+] Download do site...

##########################################################################
#                         Links encontrados                                    #
##########################################################################

https://alvo.com/login
https://alvo.com/assets/app.js

##########################################################################
#                         Hosts encontrados                                    #
##########################################################################

alvo.com
cdn.alvo.com

##########################################################################
#                            Hosts ativos                                      #
##########################################################################

[LIVE]   alvo.com        104.20.31.10
[DEAD]   cdn.alvo.com

===============================================================

Found :
        Links : 12
        Hosts : 4
===============================================================


## ğŸ§± Arquitetura Interna

O fluxo de execuÃ§Ã£o segue a ordem:

1. ğŸ” VerificaÃ§Ã£o de dependÃªncias
    
2. ğŸ— CriaÃ§Ã£o de diretÃ³rio temporÃ¡rio seguro
    
3. ğŸ“¥ Download / abertura do arquivo
    
4. ğŸ” ExtraÃ§Ã£o de links (href/action)
    
5. ğŸŒ ExtraÃ§Ã£o de hosts
    
6. ğŸ§ª Testes de DNS
    
7. ğŸ¨ ExibiÃ§Ã£o formatada
    
8. 